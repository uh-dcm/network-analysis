{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas nltk numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading co-occurance network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data/textnet_rasismi.csv'\n",
    "data = open( data, encoding=\"utf8\" ).readlines()\n",
    "words_data = [ line.lower().split() for line in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we would usually do a lot of language preproceessing\n",
    " # * Stemming or lemming\n",
    " # * Removing stopwords\n",
    " # * Remove common and rare words\n",
    "\n",
    "## (not part of this course so we do not do that)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate word co-oocutance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_bigram = [list(bigrams(line)) for line in words_data ]\n",
    "\n",
    "co_occurance = list(itertools.chain(*terms_bigram))\n",
    "co_occurance_counts = collections.Counter(co_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "import random\n",
    "\n",
    "# Create connections between nodes\n",
    "for words, count in co_occurance_counts.most_common( 60 ):\n",
    "    G.add_edge( words[0], words[1], weight=( count * 5) )\n",
    "\n",
    "print( G.number_of_edges() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, k=2)\n",
    "\n",
    "nx.draw_networkx(G, pos,\n",
    "    font_size=16,\n",
    "    width=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
